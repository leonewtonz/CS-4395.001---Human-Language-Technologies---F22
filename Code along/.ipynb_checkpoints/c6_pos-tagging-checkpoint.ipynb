{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7bcbd1",
   "metadata": {},
   "source": [
    "# Chapter 6 - POS_Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399635a3",
   "metadata": {},
   "source": [
    "## Approaches to POS tagging\n",
    "1. Rule-based tagging\n",
    "2. HMM and the Viterbi algorithm\n",
    "3. Statistical approaches\n",
    "4. ML approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089fff99",
   "metadata": {},
   "source": [
    "## Approach 4: Machine learning approaches\n",
    "1. NLTK\n",
    "2. TextBlob\n",
    "3. SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31d65d",
   "metadata": {},
   "source": [
    "## NLTK\n",
    "- For detail explaination. Click here [POS tagging in NLTK](https://github.com/leonewtonz/NLP-Basic-Python/blob/master/Part_2-Words/Chapter_06_pos_tagging/POS_NLTK.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced2da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29347252",
   "metadata": {},
   "source": [
    "The code below did a decent job. However, it missed the main verd jumped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b09cb622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('quick', 'JJ'),\n",
       " ('brown', 'NN'),\n",
       " ('fox', 'NN'),\n",
       " ('jumped', 'VBD'),\n",
       " ('over', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('lazy', 'JJ'),\n",
       " ('dog', 'NN')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'The quick brown fox jumped over the lazy dog' # Add comma quick, brown to see brown=JJ\n",
    "tokens = word_tokenize(sent)\n",
    "tags = pos_tag(tokens)\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df50e31",
   "metadata": {},
   "source": [
    "#### Pratice:\n",
    "* Use the following text\n",
    "* Perform POS Tagging\n",
    "* Make a dictionary POS -> count\n",
    "* Print the dictionary from highest to lowest count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410d9abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On an exceptionally hot evening early in July a young man came out of the garret in which he lodged in S. Place and walked slowly, as though in hesitation, towards K. bridge. He had successfully avoided meeting his landlady on the staircase. His garret was under the roof of a high, five-storied house and was more like a cupboard than a room. The landlady who provided him with garret, dinners, and attendance, lived on the floor below, and every time he went out he was obliged to pass her kitchen, the door of which invariably stood open. And each time he passed, the young man had a sick, frightened feeling, which made him scowl and feel ashamed. He was hopelessly in debt to his landlady, and was afraid of meeting her.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"On an exceptionally hot evening early in July a young man came out of the garret in which he lodged in \\\n",
    "S. Place and walked slowly, as though in hesitation, towards K. bridge. \\\n",
    "He had successfully avoided meeting his landlady on the staircase. His \\\n",
    "garret was under the roof of a high, five-storied house and was more \\\n",
    "like a cupboard than a room. The landlady who provided him with garret, \\\n",
    "dinners, and attendance, lived on the floor below, and every time \\\n",
    "he went out he was obliged to pass her kitchen, the door of which \\\n",
    "invariably stood open. And each time he passed, the young man had a \\\n",
    "sick, frightened feeling, which made him scowl and feel ashamed. He was \\\n",
    "hopelessly in debt to his landlady, and was afraid of meeting her.\"\"\"\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa8d34",
   "metadata": {},
   "source": [
    "**Perform POS Tagging**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a484f68a",
   "metadata": {},
   "source": [
    "Note: the data structure of tags is list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc1df842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('On', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('exceptionally', 'RB'),\n",
       " ('hot', 'JJ'),\n",
       " ('evening', 'VBG'),\n",
       " ('early', 'JJ'),\n",
       " ('in', 'IN'),\n",
       " ('July', 'NNP'),\n",
       " ('a', 'DT'),\n",
       " ('young', 'JJ'),\n",
       " ('man', 'NN'),\n",
       " ('came', 'VBD'),\n",
       " ('out', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('garret', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('which', 'WDT'),\n",
       " ('he', 'PRP'),\n",
       " ('lodged', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('S.', 'NNP'),\n",
       " ('Place', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('walked', 'VBD'),\n",
       " ('slowly', 'RB'),\n",
       " (',', ','),\n",
       " ('as', 'IN'),\n",
       " ('though', 'IN'),\n",
       " ('in', 'IN'),\n",
       " ('hesitation', 'NN'),\n",
       " (',', ','),\n",
       " ('towards', 'NNS'),\n",
       " ('K.', 'NNP'),\n",
       " ('bridge', 'NN'),\n",
       " ('.', '.'),\n",
       " ('He', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('successfully', 'RB'),\n",
       " ('avoided', 'VBN'),\n",
       " ('meeting', 'VBG'),\n",
       " ('his', 'PRP$'),\n",
       " ('landlady', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('staircase', 'NN'),\n",
       " ('.', '.'),\n",
       " ('His', 'PRP$'),\n",
       " ('garret', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('under', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('roof', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('high', 'JJ'),\n",
       " (',', ','),\n",
       " ('five-storied', 'JJ'),\n",
       " ('house', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('was', 'VBD'),\n",
       " ('more', 'RBR'),\n",
       " ('like', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('cupboard', 'NN'),\n",
       " ('than', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('room', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('landlady', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('provided', 'VBD'),\n",
       " ('him', 'PRP'),\n",
       " ('with', 'IN'),\n",
       " ('garret', 'NN'),\n",
       " (',', ','),\n",
       " ('dinners', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('attendance', 'NN'),\n",
       " (',', ','),\n",
       " ('lived', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('floor', 'NN'),\n",
       " ('below', 'IN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('every', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('he', 'PRP'),\n",
       " ('went', 'VBD'),\n",
       " ('out', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('obliged', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('pass', 'VB'),\n",
       " ('her', 'PRP$'),\n",
       " ('kitchen', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('door', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('which', 'WDT'),\n",
       " ('invariably', 'RB'),\n",
       " ('stood', 'VBD'),\n",
       " ('open', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('each', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('he', 'PRP'),\n",
       " ('passed', 'VBD'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('young', 'JJ'),\n",
       " ('man', 'NN'),\n",
       " ('had', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('sick', 'JJ'),\n",
       " (',', ','),\n",
       " ('frightened', 'VBD'),\n",
       " ('feeling', 'NN'),\n",
       " (',', ','),\n",
       " ('which', 'WDT'),\n",
       " ('made', 'VBD'),\n",
       " ('him', 'PRP'),\n",
       " ('scowl', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('feel', 'NN'),\n",
       " ('ashamed', 'RB'),\n",
       " ('.', '.'),\n",
       " ('He', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('hopelessly', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('debt', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('his', 'PRP$'),\n",
       " ('landlady', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('was', 'VBD'),\n",
       " ('afraid', 'VBN'),\n",
       " ('of', 'IN'),\n",
       " ('meeting', 'VBG'),\n",
       " ('her', 'PRP$'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = pos_tag(word_tokenize(text))\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06d1dea",
   "metadata": {},
   "source": [
    "**Make a dict POS -> count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95fbe08c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IN': 21,\n",
       " 'DT': 15,\n",
       " 'RB': 6,\n",
       " 'JJ': 8,\n",
       " 'VBG': 3,\n",
       " 'NNP': 4,\n",
       " 'NN': 25,\n",
       " 'VBD': 17,\n",
       " 'WDT': 3,\n",
       " 'PRP': 8,\n",
       " 'CC': 7,\n",
       " ',': 12,\n",
       " 'NNS': 2,\n",
       " '.': 6,\n",
       " 'VBN': 3,\n",
       " 'PRP$': 5,\n",
       " 'RBR': 1,\n",
       " 'WP': 1,\n",
       " 'TO': 2,\n",
       " 'VB': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict = {}\n",
    "for token, pos in tags:\n",
    "    if pos in pos_dict:\n",
    "        pos_dict[pos] += 1\n",
    "    else:\n",
    "        pos_dict[pos] = 1\n",
    "pos_dict # display the pos_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ef11c5",
   "metadata": {},
   "source": [
    "**Print pos_dict from highest to lowest count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71ba53b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN : 25\n",
      "IN : 21\n",
      "VBD : 17\n",
      "DT : 15\n",
      ", : 12\n",
      "JJ : 8\n",
      "PRP : 8\n",
      "CC : 7\n",
      "RB : 6\n",
      ". : 6\n",
      "PRP$ : 5\n",
      "NNP : 4\n",
      "VBG : 3\n",
      "WDT : 3\n",
      "VBN : 3\n",
      "NNS : 2\n",
      "TO : 2\n",
      "RBR : 1\n",
      "WP : 1\n",
      "VB : 1\n"
     ]
    }
   ],
   "source": [
    "for pos in sorted(pos_dict, key=pos_dict.get, reverse=True):\n",
    "    print(pos, ':', pos_dict[pos])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73becc1",
   "metadata": {},
   "source": [
    "## spaCy\n",
    "- For detail explaination. Click here [spaCy](https://github.com/leonewtonz/NLP-Basic-Python/blob/master/Part_2-Words/Chapter_06_pos_tagging/SpaCy.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caef397b",
   "metadata": {},
   "source": [
    "The spaCy Python library is designed for 'industrial-strength' NLP. Read installation instructions here. You should be able to install with pip or pip3:\n",
    "\n",
    "    pip3 install -U spacy\n",
    "spaCy can also be installed with conda, or compiled from source. If you have a GPU, read the instructions for linking spacy with your cuda library.\n",
    "\n",
    "After spaCy is installed, you should download at least one pretrained model. There are three models, small, medium and large that can be downloaded as follows:\n",
    "\n",
    "    $python3 -m spacy download en_core_web_sm\n",
    "Simply change the 'sm' at the end to 'md' or 'bg' for the medium or large model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9673284",
   "metadata": {},
   "source": [
    "In cmd:\n",
    "1. spaCy installed\n",
    "2. pretrained model install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "141f83bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# load model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b315eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Since turning cautious Friday morning, the DJIA has dropped approximately 1,700 from peak to trough.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample text\n",
    "text = \"Since turning cautious Friday morning, the DJIA\\\n",
    " has dropped approximately 1,700 from peak to trough.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ceff6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Since turning cautious Friday morning, the DJIA has dropped approximately 1,700 from peak to trough."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create spacy object\n",
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e15632",
   "metadata": {},
   "source": [
    "**Display doc in details**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b3f6bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since since SCONJ IN True True\n",
      "turning turn VERB VBG True False\n",
      "cautious cautious ADJ JJ True False\n",
      "Friday Friday PROPN NNP True False\n",
      "morning morning NOUN NN True False\n",
      ", , PUNCT , False False\n",
      "the the DET DT True True\n",
      "DJIA DJIA PROPN NNP True False\n",
      "has have AUX VBZ True True\n",
      "dropped drop VERB VBN True False\n",
      "approximately approximately ADV RB True False\n",
      "1,700 1,700 NUM CD False False\n",
      "from from ADP IN True True\n",
      "peak peak NOUN NN True False\n",
      "to to ADP IN True True\n",
      "trough trough NOUN NN True False\n",
      ". . PUNCT . False False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.lemma_, token.pos_, token.tag_, token.is_alpha, token.is_stop)\n",
    "\n",
    "# other attributes: token_dep_, token_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f0e2f",
   "metadata": {},
   "source": [
    "### Some methods and features of spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "137e62f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cautious Friday morning', 'the DJIA', 'peak', 'trough']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get noun phrase\n",
    "[chunk.text for chunk in doc.noun_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55b26d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turn', 'drop']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get verb in lemmas form\n",
    "[token.lemma_ for token in doc if token.pos_ == 'VERB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8edd5d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friday DATE\n",
      "morning TIME\n",
      "approximately 1,700 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "# NER Named Entity Recognition\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "208aacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a dependency parse\n",
    "# How spaCy actual work\n",
    "\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d23a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('The quick brown fox jumped over the lazy river.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3921caca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ba15ea77a5c44474b5264a3bbeb2f93d-0\" class=\"displacy\" width=\"1625\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">jumped</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">river.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-7\" stroke-width=\"2px\" d=\"M945,264.5 C945,2.0 1450.0,2.0 1450.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ba15ea77a5c44474b5264a3bbeb2f93d-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,266.5 L1458.0,254.5 1442.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef95b20",
   "metadata": {},
   "source": [
    "## TextBlob\n",
    "- For detail explaination. Click here [TextBlob](https://github.com/leonewtonz/NLP-Basic-Python/blob/master/Part_2-Words/Chapter_06_pos_tagging/TextBlob%20Ten.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e7de4",
   "metadata": {},
   "source": [
    "In order to use TextBlob methods, import textblob, then convert text to a TextBlob object. Then, you are ready to roll."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cd57b2",
   "metadata": {},
   "source": [
    "Installing/Upgrading From the PyPI. Type the command below in cmd\n",
    "\n",
    "    pip install -U textblob\n",
    "    python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "670c1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93e4ea06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample text\n",
    "text = \"\"\"TextBlob is a Python (2 and 3) library for processing\\\n",
    " textual data. It provides a simple API for diving into common\\\n",
    " natural language processing (NLP) tasks such as part-of-speech\\\n",
    " tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\"\"\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d0dae11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert text to TextBlob object\n",
    "blob = TextBlob(text)\n",
    "blob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a48e34",
   "metadata": {},
   "source": [
    "### Ten basic features of TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c708e",
   "metadata": {},
   "source": [
    "**1. POS Tagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eddc82cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TextBlob', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('Python', 'NNP'),\n",
       " ('2', 'CD'),\n",
       " ('and', 'CC'),\n",
       " ('3', 'CD'),\n",
       " ('library', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('processing', 'VBG')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All tag already there in TextBlob object\n",
    "blob.tags[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a94d741",
   "metadata": {},
   "source": [
    "**2. Tokenize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4ace134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"TextBlob is a Python (2 and 3) library for processing textual data.\"),\n",
       " Sentence(\"It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\")]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28805deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob is a Python (2 and 3) library for processing textual data.\n",
      "It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n"
     ]
    }
   ],
   "source": [
    "for sent in blob.sentences:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11dc66de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['TextBlob', 'is', 'a', 'Python', '2', 'and', '3', 'library', 'for', 'processing', 'textual', 'data', 'It', 'provides', 'a', 'simple', 'API', 'for', 'diving', 'into', 'common', 'natural', 'language', 'processing', 'NLP', 'tasks', 'such', 'as', 'part-of-speech', 'tagging', 'noun', 'phrase', 'extraction', 'sentiment', 'analysis', 'classification', 'translation', 'and', 'more'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96e144b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TextBlob', 'textual', 'tasks', 'tagging', 'translation']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out all words start with t\n",
    "\n",
    "t_word = [w for w in blob.words if w.lower().startswith('t')]\n",
    "t_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89071dbd",
   "metadata": {},
   "source": [
    "**3. Lemmatize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ea51541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f0bc5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alumni lemmatized: alumnus\n"
     ]
    }
   ],
   "source": [
    "# Create Word object\n",
    "w = Word('alumni')\n",
    "print(w, 'lemmatized:', w.lemmatize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47ef513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "had lemmatized: had\n",
      "had lemmatized verb: have\n"
     ]
    }
   ],
   "source": [
    "# We can also lemmatize in different form/POS\n",
    "w = Word('had')\n",
    "print(w, 'lemmatized:', w.lemmatize())\n",
    "print(w, 'lemmatized verb:', w.lemmatize('v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c003f2",
   "metadata": {},
   "source": [
    "**4. WordNet Integration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28297823",
   "metadata": {},
   "source": [
    "Not sure what is it mean. Some sample code in the link."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a769e45",
   "metadata": {},
   "source": [
    "**5. Noun Phrase Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "080076e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['textblob', 'python', 'processing textual data', 'api', 'common natural language processing', 'nlp', 'noun phrase extraction', 'sentiment analysis'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ac4f2",
   "metadata": {},
   "source": [
    "**6. Ngrams**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b883201f",
   "metadata": {},
   "source": [
    "Not sure what it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b43a68d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['TextBlob', 'is', 'a']),\n",
       " WordList(['is', 'a', 'Python']),\n",
       " WordList(['a', 'Python', '2']),\n",
       " WordList(['Python', '2', 'and']),\n",
       " WordList(['2', 'and', '3']),\n",
       " WordList(['and', '3', 'library']),\n",
       " WordList(['3', 'library', 'for']),\n",
       " WordList(['library', 'for', 'processing']),\n",
       " WordList(['for', 'processing', 'textual']),\n",
       " WordList(['processing', 'textual', 'data']),\n",
       " WordList(['textual', 'data', 'It']),\n",
       " WordList(['data', 'It', 'provides']),\n",
       " WordList(['It', 'provides', 'a']),\n",
       " WordList(['provides', 'a', 'simple']),\n",
       " WordList(['a', 'simple', 'API']),\n",
       " WordList(['simple', 'API', 'for']),\n",
       " WordList(['API', 'for', 'diving']),\n",
       " WordList(['for', 'diving', 'into']),\n",
       " WordList(['diving', 'into', 'common']),\n",
       " WordList(['into', 'common', 'natural']),\n",
       " WordList(['common', 'natural', 'language']),\n",
       " WordList(['natural', 'language', 'processing']),\n",
       " WordList(['language', 'processing', 'NLP']),\n",
       " WordList(['processing', 'NLP', 'tasks']),\n",
       " WordList(['NLP', 'tasks', 'such']),\n",
       " WordList(['tasks', 'such', 'as']),\n",
       " WordList(['such', 'as', 'part-of-speech']),\n",
       " WordList(['as', 'part-of-speech', 'tagging']),\n",
       " WordList(['part-of-speech', 'tagging', 'noun']),\n",
       " WordList(['tagging', 'noun', 'phrase']),\n",
       " WordList(['noun', 'phrase', 'extraction']),\n",
       " WordList(['phrase', 'extraction', 'sentiment']),\n",
       " WordList(['extraction', 'sentiment', 'analysis']),\n",
       " WordList(['sentiment', 'analysis', 'classification']),\n",
       " WordList(['analysis', 'classification', 'translation']),\n",
       " WordList(['classification', 'translation', 'and']),\n",
       " WordList(['translation', 'and', 'more'])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e703edfb",
   "metadata": {},
   "source": [
    "**7. Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6017d402",
   "metadata": {},
   "source": [
    "Polarity ranges from -1.0 to +1.0. Subjectivity ranges from 0.0 to 1.0 where lower numbers are more objective and higher numbers are more subjective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c5348eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.06000000000000001, subjectivity=0.4514285714285714)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f0d6c5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.15000000000000002, subjectivity=0.75)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob2 = TextBlob('I hate seafood. I love spicy food')\n",
    "blob2.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920c7d6a",
   "metadata": {},
   "source": [
    "**8. Spelling Correction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ded0fb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"The stake is perfect but service is horrible\")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messy_text = ('The stake is purfect but service is horible')\n",
    "blob2 = TextBlob(messy_text)\n",
    "blob2.correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcced64",
   "metadata": {},
   "source": [
    "**9. Language Detection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ec02c",
   "metadata": {},
   "source": [
    "Use Google Translate API and requires internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "61a02057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 400: Bad Request",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m blob \u001b[38;5;241m=\u001b[39m TextBlob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHello World\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mblob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_language\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\textblob\\blob.py:597\u001b[0m, in \u001b[0;36mBaseBlob.detect_language\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;124;03m\"\"\"Detect the blob's language using the Google Translate API.\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \n\u001b[0;32m    574\u001b[0m \u001b[38;5;124;03mRequires an internet connection.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;124;03m:rtype: str\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    592\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTextBlob.detext_translate is deprecated and will be removed in a future release. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse the official Google Translate API instead.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m\n\u001b[0;32m    596\u001b[0m )\n\u001b[1;32m--> 597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\textblob\\translate.py:76\u001b[0m, in \u001b[0;36mTranslator.detect\u001b[1;34m(self, source, host, type_)\u001b[0m\n\u001b[0;32m     70\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m: source}\n\u001b[0;32m     71\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{url}\u001b[39;00m\u001b[38;5;124m&sl=auto&tk=\u001b[39m\u001b[38;5;132;01m{tk}\u001b[39;00m\u001b[38;5;124m&client=\u001b[39m\u001b[38;5;132;01m{client}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     72\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m     73\u001b[0m     tk\u001b[38;5;241m=\u001b[39m_calculate_tk(source),\n\u001b[0;32m     74\u001b[0m     client\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mte\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     75\u001b[0m )\n\u001b[1;32m---> 76\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m result, language \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m language\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\textblob\\translate.py:96\u001b[0m, in \u001b[0;36mTranslator._request\u001b[1;34m(self, url, host, type_, data)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m host \u001b[38;5;129;01mor\u001b[39;00m type_:\n\u001b[0;32m     95\u001b[0m     req\u001b[38;5;241m.\u001b[39mset_proxy(host\u001b[38;5;241m=\u001b[39mhost, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtype_)\n\u001b[1;32m---> 96\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m content \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request"
     ]
    }
   ],
   "source": [
    "blob = TextBlob('Hello World')\n",
    "blob.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "744a275f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 400: Bad Request",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m blob2 \u001b[38;5;241m=\u001b[39m TextBlob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHola amor\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mblob2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_language\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\textblob\\blob.py:597\u001b[0m, in \u001b[0;36mBaseBlob.detect_language\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;124;03m\"\"\"Detect the blob's language using the Google Translate API.\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \n\u001b[0;32m    574\u001b[0m \u001b[38;5;124;03mRequires an internet connection.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;124;03m:rtype: str\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    592\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTextBlob.detext_translate is deprecated and will be removed in a future release. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse the official Google Translate API instead.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m\n\u001b[0;32m    596\u001b[0m )\n\u001b[1;32m--> 597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\textblob\\translate.py:76\u001b[0m, in \u001b[0;36mTranslator.detect\u001b[1;34m(self, source, host, type_)\u001b[0m\n\u001b[0;32m     70\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m: source}\n\u001b[0;32m     71\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{url}\u001b[39;00m\u001b[38;5;124m&sl=auto&tk=\u001b[39m\u001b[38;5;132;01m{tk}\u001b[39;00m\u001b[38;5;124m&client=\u001b[39m\u001b[38;5;132;01m{client}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     72\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m     73\u001b[0m     tk\u001b[38;5;241m=\u001b[39m_calculate_tk(source),\n\u001b[0;32m     74\u001b[0m     client\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mte\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     75\u001b[0m )\n\u001b[1;32m---> 76\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m result, language \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m language\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\textblob\\translate.py:96\u001b[0m, in \u001b[0;36mTranslator._request\u001b[1;34m(self, url, host, type_, data)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m host \u001b[38;5;129;01mor\u001b[39;00m type_:\n\u001b[0;32m     95\u001b[0m     req\u001b[38;5;241m.\u001b[39mset_proxy(host\u001b[38;5;241m=\u001b[39mhost, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtype_)\n\u001b[1;32m---> 96\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m content \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request"
     ]
    }
   ],
   "source": [
    "blob2 = TextBlob('Hola amor')\n",
    "blob2.detect_language()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421a2111",
   "metadata": {},
   "source": [
    "**10. Open Source**\n",
    "\n",
    "TextBlob is an open source. It mean you can dig into code and learn more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
