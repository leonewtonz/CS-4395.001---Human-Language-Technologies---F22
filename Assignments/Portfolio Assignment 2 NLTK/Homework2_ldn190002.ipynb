{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbee3ef6",
   "metadata": {},
   "source": [
    "# Portfolio Assignment 2: Exploring NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313cb156",
   "metadata": {},
   "source": [
    "## Instruction Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fa8f64",
   "metadata": {},
   "source": [
    "### Step 1 - Create a Python Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01595a08",
   "metadata": {},
   "source": [
    "Python Notebook created by Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b211f2dd",
   "metadata": {},
   "source": [
    "### Step 2 - Import NLTK and libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaec7a6",
   "metadata": {},
   "source": [
    "NLTK imported and libraries installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e0805",
   "metadata": {},
   "source": [
    "### Step 3 - NLTK Text Object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccd9f53",
   "metadata": {},
   "source": [
    "Import NLTK Text Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07345d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b110795",
   "metadata": {},
   "source": [
    "**Two things about tokens() method and Text object:**\n",
    "1. Each token in tokens() method is a word or a punctuation.\n",
    "2. Each text in Text object is text document and already tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b047d33b",
   "metadata": {},
   "source": [
    "The code below extract the first 20 tokens from text1 and save it to first20_token variable. Then print out the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c696ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']', 'ETYMOLOGY', '.', '(', 'Supplied', 'by', 'a', 'Late', 'Consumptive', 'Usher', 'to', 'a', 'Grammar']\n"
     ]
    }
   ],
   "source": [
    "first20_token = []\n",
    "for i in range(0,20):\n",
    "  first20_token.append(text1.tokens[i])\n",
    "print(first20_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ae4eb",
   "metadata": {},
   "source": [
    "### Step 4 - The concordance() method in API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99217a7",
   "metadata": {},
   "source": [
    "* The code below search for the word 'sea' inside the text1. Word matching is not case sensetive.\n",
    "* Then print out 5 lines which contain the word 'sea'.\n",
    "* Each line will contain 80 character (0-79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fd154c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 455 matches:\n",
      " shall slay the dragon that is in the sea .\" -- ISAIAH \" And what thing soever \n",
      " S PLUTARCH ' S MORALS . \" The Indian Sea breedeth the most and the biggest fis\n",
      "cely had we proceeded two days on the sea , when about sunrise a great many Wha\n",
      "many Whales and other monsters of the sea , appeared . Among the former , one w\n",
      " waves on all sides , and beating the sea before him into a foam .\" -- TOOKE ' \n"
     ]
    }
   ],
   "source": [
    "text1.concordance('sea', 79, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c810248",
   "metadata": {},
   "source": [
    "### Step 5 - The count() method in API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8645231",
   "metadata": {},
   "source": [
    "* The count() method in the API work by counting the number of times this word appear in the text. The word here is a string. \n",
    "* It works the same as Python's count method because in Python the count() method return the count of how many time a object occurs in list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1982e",
   "metadata": {},
   "source": [
    "The count() method in API below count the number of time the word 'sea' appear in text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "908adf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.count('sea')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88122ff1",
   "metadata": {},
   "source": [
    "The count() method in Python below count the integer 1 inside a list name mixList which contain different type of data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "368383e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [7,8,9]\n",
    "mixList = ['str1', 'str2', 'str2', 1, 2.2, lst, 1, 1]\n",
    "mixList.count(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d1891f",
   "metadata": {},
   "source": [
    "### Step 6 - NLTK's word tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53f1fc1",
   "metadata": {},
   "source": [
    "The raw_text input is from \"Route 66 California: The End of the Trail by VOA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6387112a",
   "metadata": {},
   "source": [
    "'When Route 66 travelers cross the Colorado River into the state of California, it is easy to begin to feel like the journey is almost over. After all, California is the eighth and final state you visit. But, the end of the road in Los Angeles is still a 500-kilometer drive away. And much of that drive goes through the treacherous Mojave Desert. Eastern California’s Route 66 is broken, hot and deserted. The road passes crumbled buildings of bypassed towns. Needles is first city in California after crossing the Colorado River. It was once a major stop along Route 66 and the Old National Trails Highway. That road was built before Route 66, in 1913.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0a6c47",
   "metadata": {},
   "source": [
    "The code below tokenize the raw text into words and save them into variable tokens using NLTK's word tokenizer. Then print out the first 10 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a77b8689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When\n",
      "Route\n",
      "66\n",
      "travelers\n",
      "cross\n",
      "the\n",
      "Colorado\n",
      "River\n",
      "into\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "raw_text = 'When Route 66 travelers cross the Colorado River into the state of California, it is easy to begin to feel like the journey is almost over. After all, California is the eighth and final state you visit. But, the end of the road in Los Angeles is still a 500-kilometer drive away. And much of that drive goes through the treacherous Mojave Desert. Eastern California’s Route 66 is broken, hot and deserted. The road passes crumbled buildings of bypassed towns. Needles is first city in California after crossing the Colorado River. It was once a major stop along Route 66 and the Old National Trails Highway. That road was built before Route 66, in 1913.'\n",
    "tokens = word_tokenize(raw_text)\n",
    "for i in range(0,10):\n",
    "    print(tokens[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fb4950",
   "metadata": {},
   "source": [
    "### Step 7 - NLTK's sentence tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dd5960",
   "metadata": {},
   "source": [
    "The code below tokenize the raw text into sentences and save them into variable sentences using NLTK's sentence tokenizer. Then print out each sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb930f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When Route 66 travelers cross the Colorado River into the state of California, it is easy to begin to feel like the journey is almost over.\n",
      "After all, California is the eighth and final state you visit.\n",
      "But, the end of the road in Los Angeles is still a 500-kilometer drive away.\n",
      "And much of that drive goes through the treacherous Mojave Desert.\n",
      "Eastern California’s Route 66 is broken, hot and deserted.\n",
      "The road passes crumbled buildings of bypassed towns.\n",
      "Needles is first city in California after crossing the Colorado River.\n",
      "It was once a major stop along Route 66 and the Old National Trails Highway.\n",
      "That road was built before Route 66, in 1913.\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "sentences = sent_tokenize(raw_text)\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f6927",
   "metadata": {},
   "source": [
    "### Step 8 - NLTK's PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b243cf67",
   "metadata": {},
   "source": [
    "Stemming means removing affixes. The result may be tokens that are not actually words or have different meanings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea51060",
   "metadata": {},
   "source": [
    "The code below using list comprehension to stem the text and display the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928888d1",
   "metadata": {},
   "source": [
    "* The raw text was tokenizing into words and save them into variable tokens using NLTK's word tokenizer.\n",
    "* Then the variable tokens was stemmed into variable stemmed using NLTK's PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19f7f4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when', 'rout', '66', 'travel', 'cross', 'the', 'colorado', 'river', 'into', 'the', 'state', 'of', 'california', ',', 'it', 'is', 'easi', 'to', 'begin', 'to', 'feel', 'like', 'the', 'journey', 'is', 'almost', 'over', '.', 'after', 'all', ',', 'california', 'is', 'the', 'eighth', 'and', 'final', 'state', 'you', 'visit', '.', 'but', ',', 'the', 'end', 'of', 'the', 'road', 'in', 'lo', 'angel', 'is', 'still', 'a', '500-kilomet', 'drive', 'away', '.', 'and', 'much', 'of', 'that', 'drive', 'goe', 'through', 'the', 'treacher', 'mojav', 'desert', '.', 'eastern', 'california', '’', 's', 'rout', '66', 'is', 'broken', ',', 'hot', 'and', 'desert', '.', 'the', 'road', 'pass', 'crumbl', 'build', 'of', 'bypass', 'town', '.', 'needl', 'is', 'first', 'citi', 'in', 'california', 'after', 'cross', 'the', 'colorado', 'river', '.', 'it', 'wa', 'onc', 'a', 'major', 'stop', 'along', 'rout', '66', 'and', 'the', 'old', 'nation', 'trail', 'highway', '.', 'that', 'road', 'wa', 'built', 'befor', 'rout', '66', ',', 'in', '1913', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "tokens = word_tokenize(raw_text)\n",
    "stemmed = [stemmer.stem(t) for t in tokens]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b086c082",
   "metadata": {},
   "source": [
    "### Step 9 - NLTK's WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f7454",
   "metadata": {},
   "source": [
    "Lemmatization is similar to stemming but considers the context and converts the word to its meaningful base form, which is called Lemma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed5e3d",
   "metadata": {},
   "source": [
    "The code below using list comprehension to lemmatize the text and display the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b056068",
   "metadata": {},
   "source": [
    "* The raw text was tokenizing into words and save them into variable tokens using NLTK's word tokenizer.\n",
    "* Then the variable tokens was lemmatized into variable lemmas using NLTK's WordNetLemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecbe95d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'Route', '66', 'traveler', 'cross', 'the', 'Colorado', 'River', 'into', 'the', 'state', 'of', 'California', ',', 'it', 'is', 'easy', 'to', 'begin', 'to', 'feel', 'like', 'the', 'journey', 'is', 'almost', 'over', '.', 'After', 'all', ',', 'California', 'is', 'the', 'eighth', 'and', 'final', 'state', 'you', 'visit', '.', 'But', ',', 'the', 'end', 'of', 'the', 'road', 'in', 'Los', 'Angeles', 'is', 'still', 'a', '500-kilometer', 'drive', 'away', '.', 'And', 'much', 'of', 'that', 'drive', 'go', 'through', 'the', 'treacherous', 'Mojave', 'Desert', '.', 'Eastern', 'California', '’', 's', 'Route', '66', 'is', 'broken', ',', 'hot', 'and', 'deserted', '.', 'The', 'road', 'pass', 'crumbled', 'building', 'of', 'bypassed', 'town', '.', 'Needles', 'is', 'first', 'city', 'in', 'California', 'after', 'crossing', 'the', 'Colorado', 'River', '.', 'It', 'wa', 'once', 'a', 'major', 'stop', 'along', 'Route', '66', 'and', 'the', 'Old', 'National', 'Trails', 'Highway', '.', 'That', 'road', 'wa', 'built', 'before', 'Route', '66', ',', 'in', '1913', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "tokens = word_tokenize(raw_text)\n",
    "wnl = WordNetLemmatizer()\n",
    "lemmas = [wnl.lemmatize(t) for t in tokens]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba41000",
   "metadata": {},
   "source": [
    "Five differences in the stems verses the lemmas. (stem - lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffacf7c",
   "metadata": {},
   "source": [
    "* rout - Route\n",
    "* travel - traveler\n",
    "* treacher - treacherous\n",
    "* crumbl - crumbled\n",
    "* needl - Needles\n",
    "* citi - city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8d27f4",
   "metadata": {},
   "source": [
    "### Step 10 - Comment on NLTK libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e82c82",
   "metadata": {},
   "source": [
    "**Functionality of NLTK libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb478b47",
   "metadata": {},
   "source": [
    "* The NLTK libraries are very usefull when doing the text processing. It offers a variety methods such as word_tokenize(), sent_tokenize(), stemming, lemmatization, etc...These methods provide efficent ways to normalize and break raw text into smaller part such as word, sentence, grouping word with same root. \n",
    "* The NLTK libraries also include a lot built-in text which user can test and work right away. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3962d484",
   "metadata": {},
   "source": [
    "**Code quality of NLTK libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c28bfe",
   "metadata": {},
   "source": [
    " The NLTK libraries generate a better output on text processing compare to similar Python's method(). For example:\n",
    " * The word_tokenizer() can seperated word and punctuation better then split() method in Python without the separator specification \n",
    " * The sent_tokenizer() can perform sentence segmentation very well. NLTK will not end a sentence on just any '.'. It can recognize the different the dot in \"Dr.\" and the dot which end the sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2168ad",
   "metadata": {},
   "source": [
    "**Future project using NLTK**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac744871",
   "metadata": {},
   "source": [
    "* NLTK can be used in combination of speech recognization to analyzing a conversation.\n",
    "* NLTK can be used for sentiment analysis and evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
