{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e27d2e9",
   "metadata": {},
   "source": [
    "# Author Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34702c",
   "metadata": {},
   "source": [
    "**CS 4395 - Intro to NLP**\n",
    "\n",
    "**Dr. Karen Mazidi**\n",
    "\n",
    "**Prepare by Leo Nguyen - ldn190002**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528cba6a",
   "metadata": {},
   "source": [
    "### Instruction 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6797fd2",
   "metadata": {},
   "source": [
    "Read in cvs file using panda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360263b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('federalist.csv', header=0, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d6561",
   "metadata": {},
   "source": [
    "Convert the author column to categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7306de50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author    category\n",
       "text        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.astype({\"author\":'category'})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb420d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0584e58",
   "metadata": {},
   "source": [
    "Display first few fow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6242f5d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAMILTON</td>\n",
       "      <td>FEDERALIST. No. 1 General Introduction For the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JAY</td>\n",
       "      <td>FEDERALIST No. 2 Concerning Dangers from Forei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JAY</td>\n",
       "      <td>FEDERALIST No. 3 The Same Subject Continued (C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JAY</td>\n",
       "      <td>FEDERALIST No. 4 The Same Subject Continued (C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JAY</td>\n",
       "      <td>FEDERALIST No. 5 The Same Subject Continued (C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author                                               text\n",
       "0  HAMILTON  FEDERALIST. No. 1 General Introduction For the...\n",
       "1       JAY  FEDERALIST No. 2 Concerning Dangers from Forei...\n",
       "2       JAY  FEDERALIST No. 3 The Same Subject Continued (C...\n",
       "3       JAY  FEDERALIST No. 4 The Same Subject Continued (C...\n",
       "4       JAY  FEDERALIST No. 5 The Same Subject Continued (C..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ec715",
   "metadata": {},
   "source": [
    "Display counts by author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb1e861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HAMILTON                49\n",
       "MADISON                 15\n",
       "HAMILTON OR MADISON     11\n",
       "JAY                      5\n",
       "HAMILTON AND MADISON     3\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ea2841",
   "metadata": {},
   "source": [
    "### Instruction 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f168bd93",
   "metadata": {},
   "source": [
    "Divide into train and test (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc587d74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (66,)\n",
      "test size: (17,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.text # Predictor\n",
    "y = df.author  # Target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "print('train size:', X_train.shape)\n",
    "print('test size:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fca41bf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66    FEDERALIST No. 67 The Executive Department Fro...\n",
       "54    FEDERALIST No. 55 The Total Number of the Hous...\n",
       "68    FEDERALIST No. 69 The Real Character of the Ex...\n",
       "18    FEDERALIST No. 19 The Same Subject Continued (...\n",
       "45    FEDERALIST No. 46 The Influence of the State a...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11948430",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66                HAMILTON\n",
       "54     HAMILTON OR MADISON\n",
       "68                HAMILTON\n",
       "18    HAMILTON AND MADISON\n",
       "45                 MADISON\n",
       "Name: author, dtype: category\n",
       "Categories (5, object): ['HAMILTON', 'HAMILTON AND MADISON', 'HAMILTON OR MADISON', 'JAY', 'MADISON']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819716c9",
   "metadata": {},
   "source": [
    "### Instruction 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b27e73",
   "metadata": {},
   "source": [
    "Process the text by removing stop words and performing tf-idf vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fc4b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "vectorizer1 = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c327bd4",
   "metadata": {},
   "source": [
    "Fit to the training data only, and applied to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25b09c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply tfidf vectorizer\n",
    "X_train1 = vectorizer1.fit_transform(X_train)\n",
    "X_test1 = vectorizer1.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81caf3ad",
   "metadata": {},
   "source": [
    "Output the training set shape and the test set shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8607a1f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (66, 7876)\n",
      "[[0.         0.         0.02956872 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.03741484 0.         0.        ]]\n",
      "\n",
      "test size: (17, 7876)\n",
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.02314673 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('train size:', X_train1.shape)\n",
    "print(X_train1.toarray()[:5]) # take a peek at the data\n",
    "\n",
    "print('\\ntest size:', X_test1.shape)\n",
    "print(X_test1.toarray()[:5]) # take a peek at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a87b4d",
   "metadata": {},
   "source": [
    "### Instruction 4 - Bernoulli Naïve Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc0c39",
   "metadata": {},
   "source": [
    "#### Train the naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7824ca57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "naive_bayes1 = BernoulliNB()\n",
    "naive_bayes1.fit(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6464dcb8",
   "metadata": {},
   "source": [
    "#### Evaluate on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9caadbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0,  0],\n",
       "       [ 3,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0],\n",
       "       [ 2,  0,  0,  0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions on the test data\n",
    "pred = naive_bayes1.predict(X_test1)\n",
    "\n",
    "# print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8cc50e",
   "metadata": {},
   "source": [
    "**Output the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f563033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.5882352941176471\n",
      "precision score:  0.5882352941176471\n",
      "recall score:  0.5882352941176471\n",
      "f1 score:  0.5882352941176471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "\n",
    "print('accuracy score: ', accuracy_score(y_test, pred))\n",
    "print('precision score: ', precision_score(y_test, pred, average='micro'))\n",
    "print('recall score: ', recall_score(y_test, pred, average='micro'))\n",
    "print('f1 score: ', f1_score(y_test, pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98901bfc",
   "metadata": {},
   "source": [
    "We have a very low accuracy = 0.588 as expected. It is because when the data coming into the Bernoulli classifier is not binary, the classifier will binarize it (Our data have 5 different levels). And the classifier just guessed the predominant class, Hamilton, every time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e3559",
   "metadata": {},
   "source": [
    "### Instruction 5 - Bernoulli Naïve Bayes Model (With modified train data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed339da",
   "metadata": {},
   "source": [
    "Looking at the train data shape above, there are 7876 unique words in the vocabulary.\n",
    "\n",
    "This may be too much, and many of those words may not be helpful. \n",
    "\n",
    "Redo the vectorization with max_features option set to use only the 1000 most frequent words. In addition to the words, add bigrams as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee674063",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = TfidfVectorizer(stop_words=stopwords, max_features=1000, ngram_range=(1, 2))\n",
    "# apply tfidf vectorizer\n",
    "X_train2 = vectorizer2.fit_transform(X_train)\n",
    "X_test2 = vectorizer2.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb87aa6",
   "metadata": {},
   "source": [
    "#### Re-train the naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "152cb78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes2 = BernoulliNB()\n",
    "naive_bayes2.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8cbe06",
   "metadata": {},
   "source": [
    "#### Re-evaluate on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5927becd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0,  0],\n",
       "       [ 0,  3,  0,  0],\n",
       "       [ 1,  0,  1,  0],\n",
       "       [ 0,  0,  0,  2]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions on the test data\n",
    "pred = naive_bayes2.predict(X_test2)\n",
    "\n",
    "# print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d65db9",
   "metadata": {},
   "source": [
    "**Re-Output the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7705242f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.9411764705882353\n",
      "precision score:  0.9411764705882353\n",
      "recall score:  0.9411764705882353\n",
      "f1 score:  0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score: ', accuracy_score(y_test, pred))\n",
    "print('precision score: ', precision_score(y_test, pred, average='micro'))\n",
    "print('recall score: ', recall_score(y_test, pred, average='micro'))\n",
    "print('f1 score: ', f1_score(y_test, pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e43a1",
   "metadata": {},
   "source": [
    "We now have a very good accuracy = 0.9411 which is much higher compare to 0.5882. This happen because, we do some addition step on precessing the text. We only feature 1000 most frequent words and extract both unigrams and bigrams on the text. Then use them to predict the author."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e67fde",
   "metadata": {},
   "source": [
    "### Instruction 6 - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe11daff",
   "metadata": {},
   "source": [
    "#### Logistic Regression (With no parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d67db50",
   "metadata": {},
   "source": [
    "Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94067b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000, ngram_range=(1, 2),\n",
       "                                 stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                             &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                             &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                             &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                             &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                                             &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;,\n",
       "                                             &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;logreg&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000, ngram_range=(1, 2),\n",
       "                                 stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                             &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                             &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                             &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                             &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                                             &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;,\n",
       "                                             &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;logreg&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000, ngram_range=(1, 2),\n",
       "                stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;, &#x27;again&#x27;, &#x27;against&#x27;,\n",
       "                            &#x27;ain&#x27;, &#x27;all&#x27;, &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                            &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;, &#x27;because&#x27;,\n",
       "                            &#x27;been&#x27;, &#x27;before&#x27;, &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                            &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;, &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_features=1000, ngram_range=(1, 2),\n",
       "                                 stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all',\n",
       "                                             'am', 'an', 'and', 'any', 'are',\n",
       "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
       "                                             'because', 'been', 'before',\n",
       "                                             'being', 'below', 'between',\n",
       "                                             'both', 'but', 'by', 'can',\n",
       "                                             'couldn', \"couldn't\", ...})),\n",
       "                ('logreg', LogisticRegression())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe1 = Pipeline([\n",
    "        ('tfidf',  TfidfVectorizer(stop_words=stopwords, max_features=1000, ngram_range=(1, 2))),\n",
    "        ('logreg', LogisticRegression()),\n",
    "])\n",
    "\n",
    "pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa8e301",
   "metadata": {},
   "source": [
    "Train the Logistic Regression classifier\n",
    "\n",
    "Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cbdef24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.5882352941176471\n",
      "precision score:  0.5882352941176471\n",
      "recall score:  0.5882352941176471\n",
      "f1 score:  0.5882352941176471\n"
     ]
    }
   ],
   "source": [
    "pred3 = pipe1.predict(X_test)\n",
    "print('accuracy score: ', accuracy_score(y_test, pred3))\n",
    "print('precision score: ', precision_score(y_test, pred3, average='micro'))\n",
    "print('recall score: ', recall_score(y_test, pred3, average='micro'))\n",
    "print('f1 score: ', f1_score(y_test, pred3, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87dac4b",
   "metadata": {},
   "source": [
    "#### Logistic Regression (With parameter adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d35b694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000, ngram_range=(1, 2),\n",
       "                                 stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                             &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                             &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                             &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                             &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                                             &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;,\n",
       "                                             &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;logreg&#x27;, LogisticRegression(class_weight=&#x27;balanced&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(max_features=1000, ngram_range=(1, 2),\n",
       "                                 stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                             &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                             &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                             &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                             &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                                             &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;,\n",
       "                                             &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;logreg&#x27;, LogisticRegression(class_weight=&#x27;balanced&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000, ngram_range=(1, 2),\n",
       "                stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;, &#x27;again&#x27;, &#x27;against&#x27;,\n",
       "                            &#x27;ain&#x27;, &#x27;all&#x27;, &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                            &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;, &#x27;because&#x27;,\n",
       "                            &#x27;been&#x27;, &#x27;before&#x27;, &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                            &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;, &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_features=1000, ngram_range=(1, 2),\n",
       "                                 stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all',\n",
       "                                             'am', 'an', 'and', 'any', 'are',\n",
       "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
       "                                             'because', 'been', 'before',\n",
       "                                             'being', 'below', 'between',\n",
       "                                             'both', 'but', 'by', 'can',\n",
       "                                             'couldn', \"couldn't\", ...})),\n",
       "                ('logreg', LogisticRegression(class_weight='balanced'))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2 = Pipeline([\n",
    "        ('tfidf',  TfidfVectorizer(stop_words=stopwords, max_features=1000, ngram_range=(1, 2))),\n",
    "        ('logreg', LogisticRegression(solver='lbfgs', class_weight='balanced')),\n",
    "])\n",
    "\n",
    "pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f18b2",
   "metadata": {},
   "source": [
    "Re train and evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14603018",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.7647058823529411\n",
      "precision score:  0.7647058823529411\n",
      "recall score:  0.7647058823529411\n",
      "f1 score:  0.7647058823529412\n"
     ]
    }
   ],
   "source": [
    "pred4 = pipe2.predict(X_test)\n",
    "print('accuracy score: ', accuracy_score(y_test, pred4))\n",
    "print('precision score: ', precision_score(y_test, pred4, average='micro'))\n",
    "print('recall score: ', recall_score(y_test, pred4, average='micro'))\n",
    "print('f1 score: ', f1_score(y_test, pred4, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250ea6a7",
   "metadata": {},
   "source": [
    "**Compare result between 2 Logistic Regession Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eceb85a",
   "metadata": {},
   "source": [
    "We have a big improvement on accuracy from 0.588 to 0.764. It is because we now specify the class_weight to balance which mean we will adjust the weight of each author prediction result based on the error that the model learned. If not all author will have the same weight which we know is not true as we know from previous result, the predominant class is Hamilton."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9ed0c7",
   "metadata": {},
   "source": [
    "### Instruction 7 - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0269449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aecd980",
   "metadata": {},
   "source": [
    "#### A network of (15, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75b877ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.6470588235294118\n",
      "precision score:  0.6470588235294118\n",
      "recall score:  0.6470588235294118\n",
      "f1 score:  0.6470588235294118\n"
     ]
    }
   ],
   "source": [
    "pipe71 = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words=stopwords, max_features=1000, ngram_range=(1, 2))),\n",
    "        ('neuralnet', MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                   hidden_layer_sizes=(15, 2), random_state=1)),\n",
    "         ])\n",
    "\n",
    "pipe71.fit(X_train, y_train)\n",
    "\n",
    "pred = pipe71.predict(X_test)\n",
    "print('accuracy score: ', accuracy_score(y_test, pred))\n",
    "print('precision score: ', precision_score(y_test, pred, average='micro'))\n",
    "print('recall score: ', recall_score(y_test, pred, average='micro'))\n",
    "print('f1 score: ', f1_score(y_test, pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb39dc1b",
   "metadata": {},
   "source": [
    "#### A network of  (100, 67, 15, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9d9fd6b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.7058823529411765\n",
      "precision score:  0.7058823529411765\n",
      "recall score:  0.7058823529411765\n",
      "f1 score:  0.7058823529411765\n"
     ]
    }
   ],
   "source": [
    "pipe72 = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words=stopwords, max_features=1000, ngram_range=(1, 2))),\n",
    "        ('neuralnet', MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                   hidden_layer_sizes=(100, 67, 15, 7), random_state=1)),\n",
    "         ])\n",
    "\n",
    "pipe72.fit(X_train, y_train)\n",
    "\n",
    "pred = pipe72.predict(X_test)\n",
    "print('accuracy score: ', accuracy_score(y_test, pred))\n",
    "print('precision score: ', precision_score(y_test, pred, average='micro'))\n",
    "print('recall score: ', recall_score(y_test, pred, average='micro'))\n",
    "print('f1 score: ', f1_score(y_test, pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e2a363",
   "metadata": {},
   "source": [
    "#### A network of   (21, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b48a8a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.8235294117647058\n",
      "precision score:  0.8235294117647058\n",
      "recall score:  0.8235294117647058\n",
      "f1 score:  0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "pipe73 = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words=stopwords, max_features=1000, ngram_range=(1, 2))),\n",
    "        ('neuralnet', MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                   hidden_layer_sizes=(21, 7), random_state=1)),\n",
    "         ])\n",
    "\n",
    "pipe73.fit(X_train, y_train)\n",
    "\n",
    "pred = pipe73.predict(X_test)\n",
    "print('accuracy score: ', accuracy_score(y_test, pred))\n",
    "print('precision score: ', precision_score(y_test, pred, average='micro'))\n",
    "print('recall score: ', recall_score(y_test, pred, average='micro'))\n",
    "print('f1 score: ', f1_score(y_test, pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3af72ac",
   "metadata": {},
   "source": [
    "After a several trial and error we can see that the network of (21, 7) got 82.3% accuracy, the network of (100, 67, 15, 7) got 70.5% accuracy and the network of (15, 2) got 64.7% accuracy. There is no suprise there, it is because even though the the network of (100, 67, 15, 7) have more nodes and hidden layers compare to other two, it is still do not have the highest accuracy among 3 topologies. One of reason is that, it failed the 3rd rules when choosen the number nodes, which is too much. It should be smaller than the 2x of input layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
