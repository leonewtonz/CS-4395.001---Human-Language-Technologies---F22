{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "133355dc",
   "metadata": {},
   "source": [
    "# Text Classicaition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30434104",
   "metadata": {},
   "source": [
    "**CS 4395 - Intro to NLP**\n",
    "\n",
    "**Dr. Karen Mazidi**\n",
    "\n",
    "**Prepare by Leo Nguyen - ldn190002**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6598cc7",
   "metadata": {},
   "source": [
    "### Instruction 1\n",
    "\n",
    "    - Find a text classification data set that interests you. \n",
    "    - Divide into train/test\n",
    "    - Create a graph showing the distribution of the target classes.\n",
    "    - Describe the data set and what the model should be able to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f3e115",
   "metadata": {},
   "source": [
    "Import all require modules an packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f1c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import datasets, layers, models, preprocessing\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e970fa7",
   "metadata": {},
   "source": [
    "Read the dataset. Only read the: title, text and lable. Ignore the index column in the cvs file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f40a962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows and columns: (72134, 3)\n",
      "                                               title  \\\n",
      "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
      "1                                                NaN   \n",
      "2  UNBELIEVABLE! OBAMAâS ATTORNEY GENERAL SAYS ...   \n",
      "3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
      "4  SATAN 2: Russia unvelis an image of its terrif...   \n",
      "\n",
      "                                                text  label  \n",
      "0  No comment is expected from Barack Obama Membe...      1  \n",
      "1     Did they post their votes for Hillary already?      1  \n",
      "2   Now, most of the demonstrators gathered last ...      1  \n",
      "3  A dozen politically active pastors came here f...      0  \n",
      "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('WELFake_Dataset.csv', header=0, usecols=[1,2,3], encoding='latin-1')\n",
    "print('rows and columns:', df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a59fd5c",
   "metadata": {},
   "source": [
    "Check the NAs value in entire dataset. Show counts for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b29fa6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    558\n",
       "text      39\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f95801",
   "metadata": {},
   "source": [
    "**Do some clean up on dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220aa99",
   "metadata": {},
   "source": [
    "Delete rows with NAs. And output the new dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "159f5691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensions of data frame: (71537, 3)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print('\\nDimensions of data frame:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f0a66",
   "metadata": {},
   "source": [
    "**Divide into train/test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1af0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size:  (57199, 3)\n",
      "test data size:  (14338, 3)\n"
     ]
    }
   ],
   "source": [
    "# split df into train and test\n",
    "i = np.random.rand(len(df)) < 0.8\n",
    "train = df[i]\n",
    "test = df[~i]\n",
    "print(\"train data size: \", train.shape)\n",
    "print(\"test data size: \", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4becb51",
   "metadata": {},
   "source": [
    "**Graph showing the distribution of the target classes for entire dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61306776",
   "metadata": {},
   "source": [
    "The target class is the **label** column which classify which news is real, which is fake.\n",
    "\n",
    "Based on the graph, we can see that, we have almost equal amount of fake news and real news on the dataset.\n",
    "\n",
    "Label (0 = fake and 1 = real)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e22215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x19d78eb5210>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.catplot(data=df, x=\"label\", kind='count').set(title='Distribution of Fake - 0 /Real - 1 News')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15888f0f",
   "metadata": {},
   "source": [
    "**Describe the data set and what the model should be able to predict.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd314716",
   "metadata": {},
   "source": [
    "    - Fake News Classification: https://www.kaggle.com/datasets/saurabhshahane/fake-news-classification\n",
    "    \n",
    "    - The dataset contains of 72,134 news articles with 35,028 real and 37,106 fake news. The dataset was merged from four popular news datasets: Kaggle, McIntire, Reuters, BuzzFeed Political to prevent over-fitting of classifiers and to provide more text data for better ML training.\n",
    "\n",
    "    - Dataset contains four columns: Serial number (starting from 0); Title (about the text news heading); Text (about the news content); and Label (0 = fake and 1 = real).\n",
    "\n",
    "    - However there is some NAs value inside the original dataset. After cleaning (Remove NAs value). The number of articles was reduce from 72,134 to 71,537.\n",
    "\n",
    "    - Cleaned dataset is divided into train/test (80/20). Then use the train set to build the model to predict which articles is real, which is fake. (0 = fake and 1 = real). \n",
    "    \n",
    "     - The models only use \"text\" column as a predictor to predict \"label\" columns. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc324f7",
   "metadata": {},
   "source": [
    "### Intruction 2 - Sequential Model\n",
    "\n",
    "    - Create a sequential model\n",
    "    - Evaluate on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e5a758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNBELIEVABLE! OBAMAâS ATTORNEY GENERAL SAYS ...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>About Time! Christian Group Sues Amazon and SP...</td>\n",
       "      <td>All we can say on this one is it s about time ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "2  UNBELIEVABLE! OBAMAâS ATTORNEY GENERAL SAYS ...   \n",
       "3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "5  About Time! Christian Group Sues Amazon and SP...   \n",
       "\n",
       "                                                text  label  \n",
       "0  No comment is expected from Barack Obama Membe...      1  \n",
       "2   Now, most of the demonstrators gathered last ...      1  \n",
       "3  A dozen politically active pastors came here f...      0  \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n",
       "5  All we can say on this one is it s about time ...      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3986b3",
   "metadata": {},
   "source": [
    "**Create a sequential model**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06d983f9",
   "metadata": {},
   "source": [
    "Prepare the data before building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6202e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shapes: (57199, 25000) (57199,)\n",
      "test shapes: (14338, 25000) (14338,)\n",
      "test first five labels: [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# set up X and Y\n",
    "num_labels = 2\n",
    "vocab_size = 25000\n",
    "batch_size = 100\n",
    "\n",
    "# fit the tokenizer on the training data\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(train.text) # Only use text column as the predictor for the models\n",
    "\n",
    "x_train = tokenizer.texts_to_matrix(train.text, mode='tfidf')\n",
    "x_test = tokenizer.texts_to_matrix(test.text, mode='tfidf')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train.label)\n",
    "y_train = encoder.transform(train.label)\n",
    "y_test = encoder.transform(test.label)\n",
    "\n",
    "# check shape\n",
    "print(\"train shapes:\", x_train.shape, y_train.shape)\n",
    "print(\"test shapes:\", x_test.shape, y_test.shape)\n",
    "print(\"test first five labels:\", y_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57188e77",
   "metadata": {},
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "145e1637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "515/515 [==============================] - 35s 63ms/step - loss: 0.1646 - accuracy: 0.9462 - val_loss: 0.0894 - val_accuracy: 0.9722\n",
      "Epoch 2/30\n",
      "515/515 [==============================] - 16s 31ms/step - loss: 0.0296 - accuracy: 0.9930 - val_loss: 0.0889 - val_accuracy: 0.9771\n",
      "Epoch 3/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 0.0101 - accuracy: 0.9988 - val_loss: 0.0948 - val_accuracy: 0.9759\n",
      "Epoch 4/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.1256 - val_accuracy: 0.9753\n",
      "Epoch 5/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.1296 - val_accuracy: 0.9752\n",
      "Epoch 6/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 0.0074 - accuracy: 0.9986 - val_loss: 0.1387 - val_accuracy: 0.9724\n",
      "Epoch 7/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.1529 - val_accuracy: 0.9743\n",
      "Epoch 8/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.1529 - val_accuracy: 0.9740\n",
      "Epoch 9/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.1542 - val_accuracy: 0.9745\n",
      "Epoch 10/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.1637 - val_accuracy: 0.9745\n",
      "Epoch 11/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.1967 - val_accuracy: 0.9715\n",
      "Epoch 12/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.1745 - val_accuracy: 0.9743\n",
      "Epoch 13/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.1796 - val_accuracy: 0.9750\n",
      "Epoch 14/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 9.5645e-04 - accuracy: 0.9999 - val_loss: 0.2068 - val_accuracy: 0.9726\n",
      "Epoch 15/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 3.8724e-04 - accuracy: 1.0000 - val_loss: 0.2020 - val_accuracy: 0.9757\n",
      "Epoch 16/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 3.1645e-04 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9752\n",
      "Epoch 17/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 2.7281e-04 - accuracy: 1.0000 - val_loss: 0.2213 - val_accuracy: 0.9750\n",
      "Epoch 18/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 2.3997e-04 - accuracy: 1.0000 - val_loss: 0.2313 - val_accuracy: 0.9752\n",
      "Epoch 19/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 2.1521e-04 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9750\n",
      "Epoch 20/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 1.9436e-04 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9748\n",
      "Epoch 21/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 1.7862e-04 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9748\n",
      "Epoch 22/30\n",
      "515/515 [==============================] - 8s 16ms/step - loss: 1.6451e-04 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9747\n",
      "Epoch 23/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 1.5245e-04 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 0.9747\n",
      "Epoch 24/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 1.4418e-04 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9748\n",
      "Epoch 25/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 1.3509e-04 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9743\n",
      "Epoch 26/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 1.2891e-04 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.9745\n",
      "Epoch 27/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 1.2458e-04 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9743\n",
      "Epoch 28/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 1.1880e-04 - accuracy: 1.0000 - val_loss: 0.3292 - val_accuracy: 0.9750\n",
      "Epoch 29/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 1.1579e-04 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9740\n",
      "Epoch 30/30\n",
      "515/515 [==============================] - 8s 15ms/step - loss: 1.1046e-04 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.9747\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model1 = models.Sequential()\n",
    "model1.add(layers.Dense(32, input_dim=vocab_size, kernel_initializer='normal', activation='relu'))\n",
    "model1.add(layers.Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    " \n",
    "# compile\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "history = model1.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f55d09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                800032    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 800,065\n",
      "Trainable params: 800,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show model summary\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb6d68",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51181bc8",
   "metadata": {},
   "source": [
    "Use model to predict the target on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16234622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 3s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [9.9999946e-01],\n",
       "       [4.2885760e-24],\n",
       "       [1.0620265e-26],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions so we can calculate more metrics\n",
    "pred = model1.predict(x_test)\n",
    "pred_labels = [1 if p>0.5 else 0 for p in pred]\n",
    "pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae1e6ab",
   "metadata": {},
   "source": [
    "Evaluate and calculate the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d95dec9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.9745431719905148\n",
      "precision score:  0.9727137646899905\n",
      "recall score:  0.9778652906029331\n",
      "f1 score:  0.9752827249949211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print('accuracy score: ', accuracy_score(y_test, pred_labels))\n",
    "print('precision score: ', precision_score(y_test, pred_labels))\n",
    "print('recall score: ', recall_score(y_test, pred_labels))\n",
    "print('f1 score: ', f1_score(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d111cc64",
   "metadata": {},
   "source": [
    "### Instruction 3 - Sequential Model with RNN, CNN Architecture\n",
    "\n",
    "Try different architecture like RNN, CNN, etc and evaluate on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e8ef46",
   "metadata": {},
   "source": [
    "### RNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995bf126",
   "metadata": {},
   "source": [
    "Prepare the data before building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8e91199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different set up for X and Y \n",
    "max_features = 10000\n",
    "maxlen = 500\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# pad the data to maxlen\n",
    "train_data = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "test_data = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f910f",
   "metadata": {},
   "source": [
    "Build model with RNN Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f4c51d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "358/358 [==============================] - 46s 124ms/step - loss: 0.6938 - accuracy: 0.5047 - val_loss: 0.6933 - val_accuracy: 0.4938\n",
      "Epoch 2/10\n",
      "358/358 [==============================] - 43s 119ms/step - loss: 0.6934 - accuracy: 0.5079 - val_loss: 0.6925 - val_accuracy: 0.5122\n",
      "Epoch 3/10\n",
      "358/358 [==============================] - 43s 119ms/step - loss: 0.6936 - accuracy: 0.5063 - val_loss: 0.6923 - val_accuracy: 0.5095\n",
      "Epoch 4/10\n",
      "358/358 [==============================] - 43s 119ms/step - loss: 0.6937 - accuracy: 0.5063 - val_loss: 0.6926 - val_accuracy: 0.5109\n",
      "Epoch 5/10\n",
      "358/358 [==============================] - 44s 122ms/step - loss: 0.6929 - accuracy: 0.5094 - val_loss: 0.6940 - val_accuracy: 0.4932\n",
      "Epoch 6/10\n",
      "358/358 [==============================] - 43s 120ms/step - loss: 0.6932 - accuracy: 0.5030 - val_loss: 0.6928 - val_accuracy: 0.5106\n",
      "Epoch 7/10\n",
      "358/358 [==============================] - 42s 118ms/step - loss: 0.6930 - accuracy: 0.5102 - val_loss: 0.6961 - val_accuracy: 0.5096\n",
      "Epoch 8/10\n",
      "358/358 [==============================] - 42s 116ms/step - loss: 0.6935 - accuracy: 0.5049 - val_loss: 0.6942 - val_accuracy: 0.5097\n",
      "Epoch 9/10\n",
      "358/358 [==============================] - 42s 116ms/step - loss: 0.6931 - accuracy: 0.5020 - val_loss: 0.6931 - val_accuracy: 0.5099\n",
      "Epoch 10/10\n",
      "358/358 [==============================] - 41s 115ms/step - loss: 0.6936 - accuracy: 0.5059 - val_loss: 0.6921 - val_accuracy: 0.5097\n"
     ]
    }
   ],
   "source": [
    "# build a Sequential model with Embedding and SimpleRNN layers\n",
    "\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Embedding(max_features, 32))\n",
    "model2.add(layers.SimpleRNN(32))\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile\n",
    "model2.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "history = model2.fit(train_data,\n",
    "                    y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8614fcf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          320000    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 322,113\n",
      "Trainable params: 322,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show model summary\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddf97fa",
   "metadata": {},
   "source": [
    "**Evaluation of RNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b964d",
   "metadata": {},
   "source": [
    "Evaluate and calculate the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c640691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 10s 22ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.02      0.03      6974\n",
      "           1       0.51      0.99      0.68      7364\n",
      "\n",
      "    accuracy                           0.51     14338\n",
      "   macro avg       0.52      0.50      0.35     14338\n",
      "weighted avg       0.52      0.51      0.36     14338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# get predictions so we can calculate more metrics\n",
    "pred = model2.predict(test_data)\n",
    "pred_labels = [1 if p>0.5 else 0 for p in pred]\n",
    "print(classification_report(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a4d6ad",
   "metadata": {},
   "source": [
    "### CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc985df",
   "metadata": {},
   "source": [
    "Build model with CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75e7caa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "358/358 [==============================] - 116s 323ms/step - loss: 0.7252 - accuracy: 0.4977 - val_loss: 0.6930 - val_accuracy: 0.4983\n",
      "Epoch 2/10\n",
      "358/358 [==============================] - 115s 320ms/step - loss: 0.6935 - accuracy: 0.5026 - val_loss: 0.6928 - val_accuracy: 0.5087\n",
      "Epoch 3/10\n",
      "358/358 [==============================] - 114s 317ms/step - loss: 0.6936 - accuracy: 0.5006 - val_loss: 0.6928 - val_accuracy: 0.5087\n",
      "Epoch 4/10\n",
      "358/358 [==============================] - 113s 317ms/step - loss: 0.6936 - accuracy: 0.5025 - val_loss: 0.6934 - val_accuracy: 0.4963\n",
      "Epoch 5/10\n",
      "358/358 [==============================] - 114s 317ms/step - loss: 0.6934 - accuracy: 0.5018 - val_loss: 0.6932 - val_accuracy: 0.5087\n",
      "Epoch 6/10\n",
      "358/358 [==============================] - 116s 324ms/step - loss: 0.6933 - accuracy: 0.5002 - val_loss: 0.6926 - val_accuracy: 0.5087\n",
      "Epoch 7/10\n",
      "358/358 [==============================] - 116s 324ms/step - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.6948 - val_accuracy: 0.4962\n",
      "Epoch 8/10\n",
      "358/358 [==============================] - 114s 318ms/step - loss: 0.6929 - accuracy: 0.5065 - val_loss: 0.6945 - val_accuracy: 0.4959\n",
      "Epoch 9/10\n",
      "358/358 [==============================] - 114s 318ms/step - loss: 0.6930 - accuracy: 0.5044 - val_loss: 0.6937 - val_accuracy: 0.5087\n",
      "Epoch 10/10\n",
      "358/358 [==============================] - 113s 317ms/step - loss: 0.6931 - accuracy: 0.5047 - val_loss: 0.6924 - val_accuracy: 0.4960\n"
     ]
    }
   ],
   "source": [
    "# build a Sequential model 1D convnet\n",
    "\n",
    "model3 = models.Sequential()\n",
    "model3.add(layers.Embedding(max_features, 128, input_length=maxlen)) \n",
    "model3.add(layers.Conv1D(32, 7, activation='relu')) \n",
    "model3.add(layers.MaxPooling1D(5)) \n",
    "model3.add(layers.Conv1D(32, 7, activation='relu')) \n",
    "model3.add(layers.GlobalMaxPooling1D())\n",
    "model3.add(layers.Dense(1))\n",
    "\n",
    "# compile\n",
    "model3.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4),  # set learning rate\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "history = model3.fit(train_data,\n",
    "                    y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87a1af45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 500, 128)          1280000   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 494, 32)           28704     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 98, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 92, 32)            7200      \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 32)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,315,937\n",
      "Trainable params: 1,315,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show model summary\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbbdf38",
   "metadata": {},
   "source": [
    "**Evaluation of CNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f0905b",
   "metadata": {},
   "source": [
    "Evaluate and calculate the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea56602a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 7s 16ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.97      0.65      6974\n",
      "           1       0.54      0.04      0.07      7364\n",
      "\n",
      "    accuracy                           0.49     14338\n",
      "   macro avg       0.51      0.50      0.36     14338\n",
      "weighted avg       0.51      0.49      0.35     14338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# get predictions so we can calculate more metrics\n",
    "pred = model3.predict(test_data)\n",
    "pred_labels = [1 if p>0.5 else 0 for p in pred]\n",
    "print(classification_report(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c88e00f",
   "metadata": {},
   "source": [
    "### Instruction 4 - Model with Embedded Layer Approaches\n",
    "\n",
    "    - Try different embedding approaches and evaluate on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b66edb3",
   "metadata": {},
   "source": [
    "Preprocessing data before building and feeding into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1112754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNBELIEVABLE! OBAMAâS ATTORNEY GENERAL SAYS ...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>About Time! Christian Group Sues Amazon and SP...</td>\n",
       "      <td>All we can say on this one is it s about time ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "2  UNBELIEVABLE! OBAMAâS ATTORNEY GENERAL SAYS ...   \n",
       "3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "5  About Time! Christian Group Sues Amazon and SP...   \n",
       "\n",
       "                                                text  label  \n",
       "0  No comment is expected from Barack Obama Membe...      1  \n",
       "2   Now, most of the demonstrators gathered last ...      1  \n",
       "3  A dozen politically active pastors came here f...      0  \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n",
       "5  All we can say on this one is it s about time ...      1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6270bab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>All we can say on this one is it s about time ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  No comment is expected from Barack Obama Membe...      1\n",
       "2   Now, most of the demonstrators gathered last ...      1\n",
       "3  A dozen politically active pastors came here f...      0\n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1\n",
       "5  All we can say on this one is it s about time ...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the title from dataset\n",
    "df1 = df.drop(columns=['title'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3fb604",
   "metadata": {},
   "source": [
    "The original size of dataset is too big for my computer to process.\n",
    "\n",
    "Try with google colab. It is still not be able to process unless i upgrage to Pro Version\n",
    "\n",
    "==> Reduce the dataset to 1/3 of its original. So it could be process with my own computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beb15536",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.sample(frac=0.3)  # Reduce dataset to 1/3 of it original size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ebecd0",
   "metadata": {},
   "source": [
    "Encoding and decoding the string data so it could be vectorizer later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "574e273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['text'] = df1['text'].apply(lambda x: x.encode(\"latin-1\").decode(\"ascii\",\"ignore\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8c53ed",
   "metadata": {},
   "source": [
    "### Split into train/validation/test using fast_ml package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fca011d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels sizes of train, validation, test: 17168 2146 2147\n",
      "Samples sizes of train, validation, test: 17168 2146 2147\n"
     ]
    }
   ],
   "source": [
    "train_samples, train_labels, val_samples, val_labels, test_samples, test_labels = train_valid_test_split(df1, target = 'label', \n",
    "                                                                            train_size=0.8, valid_size=0.1, test_size=0.1)\n",
    "\n",
    "print('Labels sizes of train, validation, test:', len(train_labels), len(val_labels), len(test_labels))\n",
    "print('Samples sizes of train, validation, test:', len(train_samples), len(val_samples), len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b80fa59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17168, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7dc5e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17168,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da073bc2",
   "metadata": {},
   "source": [
    "**Set up the vectorizer**\n",
    "\n",
    "    - Use Keras's TextVectorization() function to vectorize the data, using only the top 20K words. Each sample will be truncated or padded to a length of 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b11e16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "003db9a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a word index dictionary in which words map to indices\n",
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c2d1e0",
   "metadata": {},
   "source": [
    "### Building the model:\n",
    "\n",
    "    - The model will included:\n",
    "            \n",
    "                - Several layers of Conv1D followed by pooling.\n",
    "                - Ending in a softmax classification layer.\n",
    "                - Instead of the usual Keras syntax, this example uses syntax from the Functional API:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324af097",
   "metadata": {},
   "source": [
    "**Set up the embedding layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93ec21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 128\n",
    "MAX_SEQUENCE_LENGTH = 200\n",
    "\n",
    "embedding_layer = layers.Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            input_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c8b22",
   "metadata": {},
   "source": [
    "**Building model using syntax from the Functional API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7af0df60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, None, 128)         2560128   \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, None, 128)         82048     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, None, 128)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, None, 128)         82048     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, None, 128)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, None, 128)         82048     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,822,913\n",
      "Trainable params: 2,822,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# add more layers\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "preds = layers.Dense(1, activation=\"softmax\")(x) \n",
    "model4 = keras.Model(int_sequences_input, preds)\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dee226",
   "metadata": {},
   "source": [
    "**Vectorize train and validation sets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4900aa91",
   "metadata": {},
   "source": [
    "Converting the samples/predictor of train and validation to list of string before vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f3dfa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(val_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7178c53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>If a grand jury indicts Donald Trump, one Fox ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30075</th>\n",
       "      <td>Share on Facebook Share on Twitter This is som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7079</th>\n",
       "      <td>One way or another, she s going to have to fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43755</th>\n",
       "      <td>WASHINGTON (Reuters) - The U.S. Supreme Court ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11634</th>\n",
       "      <td>Mises.org October 28, 2016 \\nA recent op-ed pi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "4702   If a grand jury indicts Donald Trump, one Fox ...\n",
       "30075  Share on Facebook Share on Twitter This is som...\n",
       "7079    One way or another, she s going to have to fa...\n",
       "43755  WASHINGTON (Reuters) - The U.S. Supreme Court ...\n",
       "11634  Mises.org October 28, 2016 \\nA recent op-ed pi..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ac6a3",
   "metadata": {},
   "source": [
    "Converting the train and validation dataframe to list of string so it can be convert to numpy array then vecterizor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac5acb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_samples.text.values.tolist()\n",
    "x_val = val_samples.text.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a4935",
   "metadata": {},
   "source": [
    "Vectorizer the data to right-pad the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f685734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in x_train])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in x_val])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb8a7a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train sample after padding: 17168\n",
      "Size of train label after padding: 17168\n"
     ]
    }
   ],
   "source": [
    "print('Size of train sample after padding:', len(x_train))\n",
    "print('Size of train label after padding:', len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25430356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of val sample after padding: 2146\n",
      "Size of val label after padding: 2146\n"
     ]
    }
   ],
   "source": [
    "print('Size of val sample after padding:', len(x_val))\n",
    "print('Size of val label after padding:', len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702171cf",
   "metadata": {},
   "source": [
    "**Train the embedded layer model**\n",
    "\n",
    "    - Binary_crossentropy is used because the final layer is have only either 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b43c8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "135/135 [==============================] - 33s 232ms/step - loss: 0.3739 - acc: 0.5086 - val_loss: 0.1804 - val_acc: 0.4902\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - 31s 229ms/step - loss: 0.1117 - acc: 0.5086 - val_loss: 0.1606 - val_acc: 0.4902\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - 31s 232ms/step - loss: 0.0561 - acc: 0.5086 - val_loss: 0.2385 - val_acc: 0.4902\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - 32s 239ms/step - loss: 0.0316 - acc: 0.5086 - val_loss: 0.1725 - val_acc: 0.4902\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - 32s 234ms/step - loss: 0.0142 - acc: 0.5086 - val_loss: 0.2503 - val_acc: 0.4902\n",
      "Epoch 6/20\n",
      "135/135 [==============================] - 31s 228ms/step - loss: 0.0115 - acc: 0.5086 - val_loss: 0.2937 - val_acc: 0.4902\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - 31s 228ms/step - loss: 0.0072 - acc: 0.5086 - val_loss: 0.3531 - val_acc: 0.4902\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - 31s 230ms/step - loss: 0.0023 - acc: 0.5086 - val_loss: 0.4437 - val_acc: 0.4902\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - 31s 228ms/step - loss: 0.0078 - acc: 0.5086 - val_loss: 0.5241 - val_acc: 0.4902\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - 31s 228ms/step - loss: 0.0012 - acc: 0.5086 - val_loss: 0.6783 - val_acc: 0.4902\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - 31s 227ms/step - loss: 0.0092 - acc: 0.5086 - val_loss: 0.6510 - val_acc: 0.4902\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - 31s 228ms/step - loss: 0.0022 - acc: 0.5086 - val_loss: 0.6193 - val_acc: 0.4902\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - 31s 228ms/step - loss: 0.0044 - acc: 0.5086 - val_loss: 0.5316 - val_acc: 0.4902\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - 31s 228ms/step - loss: 0.0020 - acc: 0.5086 - val_loss: 0.6765 - val_acc: 0.4902\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - 31s 227ms/step - loss: 9.3415e-04 - acc: 0.5086 - val_loss: 0.7531 - val_acc: 0.4902\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - 31s 230ms/step - loss: 0.0017 - acc: 0.5086 - val_loss: 0.8555 - val_acc: 0.4902\n",
      "Epoch 17/20\n",
      "135/135 [==============================] - 31s 233ms/step - loss: 4.4786e-04 - acc: 0.5086 - val_loss: 1.0549 - val_acc: 0.4902\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 31s 227ms/step - loss: 0.0024 - acc: 0.5086 - val_loss: 1.0349 - val_acc: 0.4902\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 31s 232ms/step - loss: 0.0086 - acc: 0.5086 - val_loss: 1.0098 - val_acc: 0.4902\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 31s 232ms/step - loss: 8.4002e-04 - acc: 0.5086 - val_loss: 0.9996 - val_acc: 0.4902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19d1236ebf0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile\n",
    "model4.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "# train\n",
    "model4.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91758249",
   "metadata": {},
   "source": [
    "**Evaluation using Embedded_layer approach**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244a5bd9",
   "metadata": {},
   "source": [
    "Converting test_sample dataframe to list of string\n",
    "\n",
    "Vectorizer the data to right-pad the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a3ea000",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_samples.text.values.tolist()\n",
    "test_x = vectorizer(np.array([[s] for s in test_x])).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a99aa60",
   "metadata": {},
   "source": [
    "Evaluate and calculate the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "076dd29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 1s 17ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.65      1045\n",
      "           1       0.00      0.00      0.00      1102\n",
      "\n",
      "    accuracy                           0.49      2147\n",
      "   macro avg       0.24      0.50      0.33      2147\n",
      "weighted avg       0.24      0.49      0.32      2147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = model4.predict(test_x)\n",
    "pred_labels = [np.argmax(p) for p in preds]\n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2160952",
   "metadata": {},
   "source": [
    "### Instruction 4\n",
    "\n",
    "    - Analysis of the performance of various approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6fcaff",
   "metadata": {},
   "source": [
    "    - Among the 4 different approaches: Dense Sequential, RNN, CNN and Embedded Layer. The 1st approach-Dense Sequential have the most accuracy number (97%). That is a very high result even though we only use simple one hidden layer with 32 nodes. It is becauase Dense Sequential performs a matrix-vector multiplication which can learns features from all combinational features of the previous layer.\n",
    "    \n",
    "    - The 2nd approach-RNN have its accuracy drop significantly compare to Dense Sequential from 97% to 51%. It is because event though RNN is more suitable for text compate to CNN. It will not perform well on a long sequence of text which is exactly the case of this dataset example when we have around 20,000 word vocabulary. \n",
    "    \n",
    "    - The 3nd approach-CNN also have a very low accuracy which is 49%. This number is even lower than the RNN because, CNN usualy work better on images or video processing. And our dataset is purely string of text.\n",
    "    \n",
    "    - The last approach-Embedded Layer also have a very low and simlar accuracy to CNN which is 49%. It is because this approach is very hard to train, especially the softmax function was used as activartor. Moreover, the poor performance also come from the fact that have a very large categories - size of vocabulary = word_index = 20,000. Together with this large number and the nature of word after vectorizer is usually not distributed uniformally lead to the insufficient utilizing of vector."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
