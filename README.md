# Course Description

Introduction to human language technologies (HLT), the study of natural languages from a computational perspective. Topics include computational models of syntax and semantics, natural language applications (such as machine translation, speech processing, information retrieval, and information extraction), and general machine-learning techniques commonly used in state-of-theart HLT research.

# Learning Objectives/Outcomes

1. Be able to perform morphological analysis
2. Be able to compute n-gram statistics and to perform smoothing
3. Demonstrate knowledge about parts-of-speech and ability to use and understand part-ofspeech
taggers
4. Demonstrate knowledge about various parsing algorithms and parsing techniques
5. Demonstrate knowledge of semantic representations including FrameNet, WordNet,
PropBank and semantic parsing techniques that employ them
6. Demonstrate knowledge about statistical machine translation
7. Be able to apply the NLP techniques to modern applications

# Assignments List

## 1. Portfolio Setup

-	GitHub portfolio for [CS 4395.001 - Human Language Technologies - F22](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22)
-	An introduction summarizing historical, current approaches to NLP and reflect on my personal interest in NLP [Overview of NLP.pdf](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/Portfolio%20Setup/Overview%20of%20NLP_ldn190002.pdf)

## 2. Assignment 1 - Text Processing with Python
-	This program will read a .csv file which contains employees information. Then it will process the text to be more standardized. If the program can not auto format, it will ask user to re-enter a formattable value
-	How to run:
	- Open terminal. Go to folder contains Homework1_ldn190002.py
	- Type in "python" to open python shell
	- Type in "py Homework1_ldn190002.py data/data.csv" to run the file.
	- Make sure the filepath data/data.csv is in the same folder with Homework1_ldn190002.py
	- Then follow the program's prompt
-	Python make it very easy to work with sysarg, and file I/O. It also have useful build-in libraries and methods to processing text file such as re, split(), splitline(), etc. However, in some cases, python will require extra step after the text was tokenize. That is why NLTK is the better option to processing text. For example: NLTK can perform the sentences segmentation way better then build-in python methods.
	- raw_text = 'Mr. Smith went to Dr. Jones. Dr. Jones was trained in the U.S.A.'
	- NLTK will not end a sentence on just any '.'.
	- The sent_tokenize(raw_text) will output ['Mr. Smith went to Dr. Jones.', 'Dr. Jones was trained in the U.S.A.']
	
-	This assignment gives me a quick review on how to work on sysarg and handle file I/O. It also provide very useful practice on how to process and format text. Writing a class in Python is very simple and similar with Java.

-	Link to [Assignment 1 - Text Processing with Python](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/tree/main/Assignments/Homework1)

## 3. Portfolio Assignment 2: NLTK
-	Exploring NLTK using Jupyter Notebook.
-	Explanation and sample code on some basic NLTK methods. [Exploring NLTK](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/Portfolio%20Assignment%202%20NLTK/Homework2_ldn190002.pdf)


## 4. Word Guessing Game
-	Exploring more NLTK features:
	+	Reprocessing
	+	Tokenizing
	+	Lemmatizing
	+	POS Tagging
-	Creating simple Word Guessing Game. Link for source code [Word_Guessing_Game](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/Word%20Guessing%20Game/Word_Guessing_Game.py)


## 5. WordNet
-	Exploring WordNet features. Link for documentation [WordNet.pdf](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/WordNet/WordNet.pdf)

## 6. Ngrams
-	Create unigrams and bigrams dictionaries for English, French, Italian. Then save them to pickle. Click here for source code [program1.py](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/N-gram/program1.py)
	+	Note: 
		*	Make sure 3 filenames are in the ngram_files folder. And this folder is in the same directory of program1.py.
    	*	For example: "ngram_files/LangId.train.English"
 -	Unpacking the pickle, calculating the probability for each language, outputting the accuracy and line of incorrectly classified items. Click for for source code [program2.py](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/N-gram/program2.py)
-	An overview of ngram. [Overview of Ngrams](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/N-gram/Overview%20of%20Ngrams.pdf)


## 7. Web Crawler

-	Objectives:
	+	Understand the importance of corpora in NLP tasks
	+	Understand basic HTML
	+	Understand how websites work
	+	Be able to do web scrapping with Beautiful Soup
	+	Create a web crawler
	+	Create a searchable knowledge base (Can be used for chatbot)

-	Source Code [web_crawler.py](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/Web%20Crawler/web_crawler.py)

-	Narrative document [NarrativeWebCrawler.pdf](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/Web%20Crawler/NarrativeWebCrawler.pdf)

## 8. Syntax Parsing

-	Objective:
	+	Understand concepts related to sentence syntax.
	+	Understand 3 types of sentence parses: PSG, Dependency, SRL
	
-	Overview and demon of 3 types on sample sentence. [Syntax Parsing](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/Syntax%20Parsing/Syntax%20Parsing.pdf)

## 9. Author Attribution

-	Objectives:

	+	Gain experience with machine learning using sklearn
	+	Experiment with the NLP task author attribution
	
-	Document and sample run: [Author_Attribution](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/Author%20Attribution/Author_Attribution.pdf)


## 10. Reading ACL Papers
-	[ACL_summary](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/ACL%20Paper%20Summary/ACL_summary.pdf)


## 11. Chatbot

-	This is rule_based chatbot which will give the basic answer in cyberpunk topic. All data was collected from https://www.neondystopia.com/

-	Objective:
	
	+ Create a chatbot using NLP techniques learned in class. 
	+ The chatbot should be able to carry on a limited conversation in a particular domain using a knowledge base or knowledge from the web, and knowledge it learns from the user.

-	Report [chatbot_report](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/Chatbot%20Project/chatbot_report.pdf)
	

-	Chatbot system requires 3 files to run:

	+ [chatbot.py](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/Chatbot%20Project/chatbot.py)
	+ [knowledge_base.py](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/Chatbot%20Project/knowledge_base.py)
	+ [stopwords.txt](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/Chatbot%20Project/stopwords.txt)
	
	
-	To run: Simply type in command_line : py chatbot.py
			
## 12. Text Classification

-	Objectives:

	• Gain experience with Keras
	• Gain experience with text classification
	• Gain experience with deep learning model variations and embeddings
	
	Try 4 different approaches: Dense Sequential, RNN, CNN, Embedded Layer
	
	Document [Text_Classification](https://github.com/leonewtonz/CS-4395.001---Human-Language-Technologies---F22/blob/main/Assignments/Text%20Classification/Text_Classification.pdf)
	
-	Dataset from Kaggle : Fake News Classification:
https://www.kaggle.com/datasets/saurabhshahane/fake-newsclassification